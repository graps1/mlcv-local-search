

\section{Algorithms} \label{sec:algorithms}

We are now ready to present a local search algorithm that greedily improves a given partition (algorithm \emph{\nameref{alg:greedy1}}). This algorithm takes as input a set of vertices, an indexing that is used as the initial value and a stopping criterion that depends on the number of iterations and the current indexing. In every iteration, it generates the neighbourhood of the current indexing through application of algorithm \emph{\nameref{alg:moveenum}} (line \ref{alg:greedy1:l1}). Afterwards, in line \ref{alg:greedy1:l2}, the neighbour with the best improvement is selected. If there is no neighbour that yields any better value (i.e. the difference computed in line \ref{alg:greedy1:l2} is negative or zero), a local minima was found and the current indexing is returned (line \ref{alg:greedy1:l3}). Otherwise, the algorithm just continues (line \ref{alg:greedy1:l4}). \\
Considering an indexing $\idx$, one can see that the amount of possible neighbours is bounded by $O(|V| \cdot |\Pi(\idx) |)$ -- this becomes clear by introspection of algorithm \emph{\nameref{alg:moveenum}}, since for every vertex, there are at maximum $|\image(\idx)| = |\Pi(\idx)|$ candidates for $k$. Fully computing the improvement of a neighbour in line \ref{alg:greedy1:l2} is closely bounded by $O(|V|^2)$ steps, since one has to compute almost all possible 2-ary combinations of vertices. Combining this with the size of the neighbourhood, one obtains an overall upper bound of $O(|V|^3 \cdot |\Pi(\idx)|)$ required steps for computing the best neighbour. The remainder, i.e. line \ref{alg:greedy1:l3} and \ref{alg:greedy1:l4}, can be computed in constant time if one does not recompute the improvement of $\move{\idx}{v^*}{k^*}$ over $\idx$ or copies the whole indexing. Since the amount of sets in a partition is bounded by $|V|$, we obtain an upper bound of $O(|V|^4)$ steps per iteration. However, if we assume that the maximal number of iterations is bounded by a constant, this complexity propagates to the complete algorithm\footnote{Although it would make sense to choose the stopping criterion dependent on the number of vertices, since in each iteration, there is only one vertex that is moved, and the overall number of vertices might be too high to reach an optimal solution in time.}.

\begin{algorithm}[ht]
    \algotitle{GS}{alg:greedy1.title}
    \SetAlgoLined
    \DontPrintSemicolon
    \KwIn{Set of vertices $V$ with indexing $\idx$ and stopping criterion $\mathrm{stop} : \N \times [n]^V \rightarrow \{0,1\}$. }
    \KwResult{Better indexing $\varidx$ }
    Let $i := 1$ \;
    \While{not $\mathrm{stop}(i, \idx)$}{
        Let $(v_1, k_1),\dots,(v_m, k_m)$ be the output from algorithm \emph{\nameref{alg:moveenum}} on input $V$, $\idx$ \label{alg:greedy1:l1} \;
        $(v^*,k^*) := \argmax_{(v_i,k_i)} J( \Pi(\idx), \Pi(\move{\idx}{v_i}{k_i}) )$ \label{alg:greedy1:l2} \;
        \If{$J( \Pi(\idx), \Pi(\move{\idx}{v^*}{k^*}) ) \leq 0$}{
            \Return{$\idx$} \label{alg:greedy1:l3} \;
        }
        Set $\idx := \move{\idx}{v^*}{k^*}$ and $i := i+1$ \label{alg:greedy1:l4} \;
    }
    \Return{$\idx$}
    \caption{Greedy-Search (GS)} \label{alg:greedy1}
\end{algorithm}

A second variant of the greedy search algorithm makes use of sampling. Algorithm \emph{\nameref{alg:greedy2}} does not consider the complete neighbourhood of any indexing, but rather randomly selects a given number of $N$ neighbours (line \ref{alg:greedy2:l3}). For each of these neighbours, a fixed number of $M$ random vertices is selected (line \ref{alg:greedy2:l4}), which are used to compute the sample mean in line \ref{alg:greedy2:l5}. Another conceptual difference to algorithm \emph{\nameref{alg:greedy1}} is that instead of returning the current indexing if no neighbour yields an improvement, algorithm \emph{\nameref{alg:greedy2}} just continues (line \ref{alg:greedy2:l6} and \ref{alg:greedy2:l7}). This is because of the variance that is induced when sampling vertices or neighbours, i.e.: the selected ``best'' neighbour (line \ref{alg:greedy2:l5}) might not actually be worse than the current solution or the actual best neighbour was not sampled from the neighbourhood (line \ref{alg:greedy2:l3}).

\begin{algorithm}[ht]
    \algotitle{GSS}{alg:greedy2.title}
    \SetAlgoLined
    \DontPrintSemicolon
    \KwIn{Set of vertices $V$ with indexing $\idx$, stopping criterion $\mathrm{stop} : \N \times [n]^V \rightarrow \{0,1\}$, neighbourhood sample size $\mathrm{N}$, objective sample size $\mathrm{M}$}
    \KwResult{Better indexing $\varidx$ }
    Let $i := 1$ \label{alg:greedy2:l1} \;
    \While{not $\mathrm{stop}(i, \idx)$}{  \label{alg:greedy2:l2} 
        Let $(v_1, k_1),\dots,(v_N, k_N)$ be the output of Algorithm \emph{\nameref{alg:moverand}} on input $V$, $\idx$, $N$ \label{alg:greedy2:l3} \;
        Sample $\{u_{i,1},w_{i,1} \}, \dots,\{u_{i,M},w_{i,M}\}$ from $\binom{V\backslash\{ v_i \}}{2}$ for all $i\in \{ 1,\dots, N \}$  \label{alg:greedy2:l4}  \;
        $(v^*, k^*) := \argmax_{(v_i, v_i)} \frac{1}{M} \sum_{j=1}^M \delta(\{u_{i,j}, w_{i,j}, v_i\}, \Pi(\idx_i), \Pi(\move{\idx}{v_i}{k_i}))$  \label{alg:greedy2:l5}  \;
        \If{$\move{\idx}{v^*}{k^*}$ is an improvement over $\idx$}{ \label{alg:greedy2:l6}
            Set $\idx := \move{\idx}{v^*}{k^*}$ \label{alg:greedy2:l7} \;
        }
        Set $i := i+1$  \label{alg:greedy2:l8} \;
    }
    \Return{$\idx$}  \label{alg:greedy2:l9} 
    \caption{Greedy-Search with Sampling (GSS)} \label{alg:greedy2}
\end{algorithm}

We now want to analyze the complexity of an iteration in algorithm \emph{\nameref{alg:greedy2}}. As already discussed in section \ref{sec:random_move_order}, line \ref{alg:greedy2:l3} takes $O(|V|\cdot N)$ steps. By sampling $N \cdot M$ values in line \ref{alg:greedy2:l4}, overall $O(N \cdot M)$ steps are required. Computing the sample mean of the costs for a pair $(v_i,k_i)$ in line \ref{alg:greedy2:l5} take $O(M)$ steps, and since these costs are computed for $N$ different pairs, this yields a bound of $O(N \cdot M)$ steps. The remainder, i.e. line \ref{alg:greedy2:l7} and \ref{alg:greedy2:l8}, can be done in constant time. This leaves us with an overall bound of $O(|V|\cdot N + N \cdot M ) = O(N\cdot (|V|+M))$ steps per iteration.